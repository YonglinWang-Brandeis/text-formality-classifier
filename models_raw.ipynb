{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data ：\n",
    "- Raw Text\n",
    "\n",
    "## Models：\n",
    "-  Logistic Regression\n",
    "-  Naíve Bayes\n",
    "-  Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/loewi/Documents/GitHub/text-formality-classifier'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fertig\n",
      "fertig\n",
      "8.13s get data package ：）\n",
      "X & y prepared\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "t0 = time() \n",
    "\n",
    "path1 = 'data/formal.txt'\n",
    "with open(path1) as f:\n",
    "    corpus_formal = f.readlines()\n",
    "print(\"fertig\")\n",
    "\n",
    "path2 = 'data/informal.txt'\n",
    "with open(path2) as f:\n",
    "    corpus_informal = f.readlines()\n",
    "print(\"fertig\")\n",
    "#%%\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "X = np.array(corpus_formal+corpus_informal)\n",
    "y = np.array([0]*len(corpus_formal) + [1]*len(corpus_informal) )\n",
    "\n",
    "X, y = shuffle(X,y)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_t, X_te, y_t, y_te = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=0)\n",
    "#%%'\n",
    "all_train = dict(classes=[0, 1], #formal 0, informal 1\n",
    "                data = X_t,\n",
    "                categories=np.array(y_t))\n",
    "\n",
    "all_test = dict(classes=[0, 1], #formal 0, informal 1\n",
    "                data = X_te,\n",
    "                categories=np.array(y_te))\n",
    "\n",
    "duration = time() - t0\n",
    "print('%0.2fs get data package ：）'%duration)\n",
    "\n",
    "X_train,X_test = all_train['data'], all_test['data'] #list of strings\n",
    "y_train, y_test =all_train['categories'], all_test['categories'] #array\n",
    "print('X & y prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature import features\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer,HashingVectorizer,TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score,StratifiedKFold,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__multi_class': ('ovr', 'multinomial'),\n",
      " 'clf__solver': ('newton-cg', 'lbfgs', 'sag')}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:  7.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 00:07:49\n",
      "\n",
      "Best score: 0.754\n",
      "Best parameters set:\n",
      "\tclf__multi_class: 'ovr'\n",
      "\tclf__solver: 'newton-cg'\n"
     ]
    }
   ],
   "source": [
    "#fine tune\n",
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression()),\n",
    "                ])        \n",
    "parameters = {\n",
    "    'clf__solver': ('newton-cg', 'lbfgs','sag'),  \n",
    "    'clf__multi_class':('ovr','multinomial'),  \n",
    "    }   \n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(pipeline,parameters,n_jobs=-1, verbose=1,cv = cv)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "m, s = divmod(time() - t0, 60)\n",
    "h, m = divmod(m, 60)\n",
    "print (\"done in %02d:%02d:%02d\" % (h, m, s))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name])) \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "testing accuracy:   0.753\n"
     ]
    }
   ],
   "source": [
    "#predict\n",
    "from sklearn import metrics  \n",
    "pipeline_validated = Pipeline([\n",
    "                ('vect', HashingVectorizer()),\n",
    "\n",
    "                ('clf', LogisticRegression(\n",
    "                        solver='newton-cg',  \n",
    "                        multi_class='ovr', \n",
    "                        )),\n",
    "                ])    \n",
    "print('Training...') \n",
    "pipeline_validated.fit(X_train, y_train) \n",
    "\n",
    "pred = pipeline_validated.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"testing accuracy:   %0.3f\" % score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/raw_lg.jbl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"model/raw_lg.jbl\"\n",
    "dump(pipeline_validated, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naíve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.1, 0.01, 0.001, 0.0001),\n",
      " 'vect__max_df': (0.5, 0.75, 1.0),\n",
      " 'vect__max_features': (None, 5000, 10000, 20000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2))}\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 67.2min\n",
      "[Parallel(n_jobs=-1)]: Done 480 out of 480 | elapsed: 74.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 4446.348s\n",
      "\n",
      "Best score: 0.696\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.1\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 5000\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "# fine tune\n",
    "nbc = Pipeline([\n",
    "                ('vect', CountVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "                ])\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 20000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "#    'tfidf__use_idf': (True, False),\n",
    "#    'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__alpha': (0.1, 0.01, 0.001, 0.0001),\n",
    "}    \n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(nbc,parameters,n_jobs=-1, verbose=1, cv = cv)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in nbc.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74994023 0.75188285 0.75080693 0.74853556 0.74616695]\n",
      "training accuracy: 0.749 (+/- 0.004)\n",
      "testing accuracy:   0.746\n"
     ]
    }
   ],
   "source": [
    "#predict   \n",
    "from sklearn import metrics  \n",
    "clf_validated = Pipeline([\n",
    "                ('vect', CountVectorizer(\n",
    "                        max_df = 0.5,\n",
    "                        max_features = 5000,\n",
    "                        ngram_range = (1, 2),\n",
    "                        )),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB(alpha = 0.1)),\n",
    "                ])    \n",
    "                \n",
    "clf_validated.fit(X_train, y_train)  \n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "scores = cross_val_score(clf_validated, X_train, y_train,  cv = cv, scoring='accuracy')\n",
    "print (scores)\n",
    "score = scores.mean()\n",
    "print(\"training accuracy: %0.3f (+/- %0.3f)\" % (score, scores.std() * 2))\n",
    "              \n",
    "pred = clf_validated.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"testing accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/raw_nb.jbl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"model/raw_nb.jbl\"\n",
    "dump(clf_validated, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__max_depth': (100, 800),\n",
      " 'clf__max_features': ('auto', 20000),\n",
      " 'clf__max_leaf_nodes': (30, 300, 3000),\n",
      " 'clf__min_samples_leaf': (1, 2),\n",
      " 'clf__min_samples_split': (0.5, 1.0)}\n",
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 28.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 35.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2159.162s\n",
      "\n",
      "Best score: 0.606\n",
      "Best parameters set:\n",
      "\tclf__max_depth: 800\n",
      "\tclf__max_features: 20000\n",
      "\tclf__max_leaf_nodes: 30\n",
      "\tclf__min_samples_leaf: 2\n",
      "\tclf__min_samples_split: 0.5\n"
     ]
    }
   ],
   "source": [
    "#fine tune\n",
    "pipeline = Pipeline([\n",
    "                ('vect', HashingVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier()),\n",
    "                ])\n",
    "parameters = {\n",
    "            'clf__max_depth':(100, 800),\n",
    "            'clf__max_leaf_nodes':(30, 300, 3000),\n",
    "            'clf__min_samples_leaf':(1, 2),\n",
    "            'clf__max_features': ('auto',20000),\n",
    "            'clf__min_samples_split': (0.5, 1.0)\n",
    "}    \n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "clf = GridSearchCV(pipeline, parameters,n_jobs=-1, verbose=1, cv = cv)\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % clf.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting...\n",
      "[0.50005977 0.50005977 0.50005977 0.50005977 0.50007472]\n",
      "training accuracy: 0.500 (+/- 0.000)\n",
      "testing accuracy:   0.500\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "from sklearn import metrics  \n",
    "clf_validated = Pipeline([\n",
    "                ('vect', HashingVectorizer()),\n",
    "                ('tfidf', TfidfTransformer()),\n",
    "                ('clf', DecisionTreeClassifier(\n",
    "                        \n",
    "                        max_features = 20000,\n",
    "                        max_depth = 800,\n",
    "                        min_samples_split = 2,\n",
    "                        min_samples_leaf = 0.5,\n",
    "                        max_leaf_nodes = 30,\n",
    "        \n",
    "                        )),\n",
    "                ]) \n",
    "print('Fitting...')                \n",
    "clf_validated.fit(X_train, y_train)  \n",
    "\n",
    "cv = StratifiedKFold(n_splits= 5 ,random_state=0,shuffle=True)\n",
    "scores = cross_val_score(clf_validated, X_train, y_train,  cv = cv, scoring='accuracy')\n",
    "print (scores)\n",
    "score = scores.mean()\n",
    "print(\"training accuracy: %0.3f (+/- %0.3f)\" % (score, scores.std() * 2))\n",
    "pred = clf_validated.predict(X_test)\n",
    "score = metrics.accuracy_score(y_test, pred)\n",
    "print(\"testing accuracy:   %0.3f\" % score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/raw_dt.jbl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"model/raw_dt.jbl\"\n",
    "dump(clf_validated, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
