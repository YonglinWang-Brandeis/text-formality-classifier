{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from joblib import load\n",
    "# import warnings simplefilter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"It was a lovely weekend.\",\n",
    "        \"if you want a longterm relationship, no way\",\n",
    "        \"You love this person in a way your parents dont!\",\n",
    "        \"The president frequently injects his own words into statements he claims his supporters said on Fox News or elsewhere.\",\n",
    "        \"Mr. T’s habit of putting words in the mouths of others are not just limited to impeachment.\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred(texts, pred):\n",
    "    for txt, p in zip(texts, pred):\n",
    "        print(\"formal: \", txt) if p == 0 else print(\"informal: \", txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naíve Bayes using raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formal:  It was a lovely weekend.\n",
      "informal:  if you want a longterm relationship, no way\n",
      "informal:  You love this person in a way your parents dont!\n",
      "formal:  The president frequently injects his own words into statements he claims his supporters said on Fox News or elsewhere.\n",
      "formal:  Mr. T’s habit of putting words in the mouths of others are not just limited to impeachment.\n"
     ]
    }
   ],
   "source": [
    "pipeline_validated = load(\"model/raw_nb.jbl\")\n",
    "pred = pipeline_validated.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression using raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formal:  It was a lovely weekend.\n",
      "informal:  if you want a longterm relationship, no way\n",
      "informal:  You love this person in a way your parents dont!\n",
      "formal:  The president frequently injects his own words into statements he claims his supporters said on Fox News or elsewhere.\n",
      "formal:  Mr. T’s habit of putting words in the mouths of others are not just limited to impeachment.\n"
     ]
    }
   ],
   "source": [
    "pipeline_validated = load(\"model/raw_lg.jbl\")\n",
    "pred = pipeline_validated.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desicion Tree using raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "informal:  It was a lovely weekend.\n",
      "informal:  if you want a longterm relationship, no way\n",
      "informal:  You love this person in a way your parents dont!\n",
      "informal:  The president frequently injects his own words into statements he claims his supporters said on Fox News or elsewhere.\n",
      "informal:  Mr. T’s habit of putting words in the mouths of others are not just limited to impeachment.\n"
     ]
    }
   ],
   "source": [
    "pipeline_validated = load(\"model/raw_dt.jbl\")\n",
    "pred = pipeline_validated.predict(texts)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "formal:  It was a lovely weekend.\n",
      "formal:  if you want a longterm relationship, no way\n",
      "formal:  You love this person in a way your parents dont!\n",
      "informal:  The president frequently injects his own words into statements he claims his supporters said on Fox News or elsewhere.\n",
      "formal:  Mr. T’s habit of putting words in the mouths of others are not just limited to impeachment.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model \n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = Tokenizer(num_words = 20000)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences_new = tokenizer.texts_to_sequences(texts)\n",
    "new_texts = pad_sequences(sequences_new, maxlen = 1000) \n",
    "\n",
    "model = load_model(\"model/LSTM.h5\") \n",
    "pred = np.argmax(model.predict(new_texts), axis=1)\n",
    "print_pred(texts, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect_paths = [\"vectorizer/ent_count_vectorizer.jbl\",\n",
    "              \"vectorizer/ngram_count_vectorizer.jbl\",\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_paths = [\"model/entity_nb.jbl\",\n",
    "            \"model/entity_length_nb.jbl\",\n",
    "            \"model/fast_number_nb.jbl\"\n",
    "            \"model/n_gram_nb.jbl\"\n",
    "            \"model/readability_nb.jbl\"\n",
    "            ]\n",
    "\n",
    "lr_paths = [\"model/entity_lr.jbl\",\n",
    "            \"model/entity_length_lr.jbl\",\n",
    "            \"model/fast_number_lr.jbl\"\n",
    "            \"model/n_gram_lr.jbl\"\n",
    "            \"model/readability_lr.jbl\"\n",
    "            ]\n",
    "\n",
    "dt_paths = [\"model/entity_dt.jbl\",\n",
    "            \"model/entity_length_dt.jbl\",\n",
    "            \"model/fast_number_dt.jbl\"\n",
    "            \"model/n_gram_dt.jbl\"\n",
    "            \"model/readability_dt.jbl\"\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(clf_path, vect_path, text):\n",
    "    \"\"\"predict the category\"\"\"\n",
    "    # load the clf and vectorizer\n",
    "    clf = load(clf_path)\n",
    "    loaded_vectorizer = load(vect_path)\n",
    "    # vecotorizing\n",
    "    X_input = loaded_vectorizer.transform(text)\n",
    "    return clf.predict(X_input)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
